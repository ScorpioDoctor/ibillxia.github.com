<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: VAD | Bill's Blog]]></title>
  <link href="http://ibillxia.github.com/blog/tags/vad/atom.xml" rel="self"/>
  <link href="http://ibillxia.github.com/"/>
  <updated>2013-05-22T23:11:25+08:00</updated>
  <id>http://ibillxia.github.com/</id>
  <author>
    <name><![CDATA[Bill Xia]]></name>
    <email><![CDATA[ibillxia@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[语音信号处理之时域分析-端点检测及Python实现]]></title>
    <link href="http://ibillxia.github.com/blog/2013/05/22/audio-signal-processing-time-domain-Voice-Activity-Detection/"/>
    <updated>2013-05-22T21:14:00+08:00</updated>
    <id>http://ibillxia.github.com/blog/2013/05/22/audio-signal-processing-time-domain-Voice-Activity-Detection</id>
    <content type="html"><![CDATA[<h2>端点检测</h2>


<p>端点检测（End-Point Detection，EPD）的目标是要决定信号的语音开始和结束的位置，所以又可以称为Speech Detection或Voice Activity Detection（VAD）。
端点检测在语音预处理中扮演着一个非常重要的角色。</p>




<p>常见的端点检测方法大致可以分为如下两类：</br>
（1）时域（Time Domain）的方法：计算量比较小，因此比较容易移植到计算能力较差的嵌入式平台</br>
（a）音量：只使用音量来进行端检，是最简单的方法，但是容易对清音造成误判。另外，不同的音量计算方法得到的结果也不尽相同，至于那种方法更好也没有定论。</br>
（b）音量和过零率：以音量为主，过零率为辅，可以对清音进行较精密的检测。</br>
（2）频域（Frequency Domain）的方法：计算量相对较大。</br>
（a）频谱的变化性（Variance）：有声音的频谱变化较规律，可以作为一个判断标准。</br>
（b）频谱的Entropy：有规律的频谱的Entropy一般较小，这也可以作为一个端检的判断标准。
</p>




<p>下面我们分别从这两个方面来探讨端检的具体方法和过程。</p>




<!--more-->




<h2>时域的端检方法</h2>


<p>时域的端检方法分为只用音量的方法和同时使用音量和过零率的方法。只使用音量的方法最简单计算量也最小，我们只需要设定一个音量阈值，任何音量小于该阈值的帧
被认为是静音（silence）。这种方法的关键在于如何选取这个阈值，一种常用的方法是使用一些带标签的数据来训练得到一个阈值，使得误差最小。</p>




<p>下面我们来看看最简单的、不需要训练的方法，其代码如下：
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import wave
</span><span class='line'>import numpy as np
</span><span class='line'>import matplotlib.pyplot as plt
</span><span class='line'>import Volume as vp
</span><span class='line'>
</span><span class='line'>fw = wave.open('sunday.wav','r')
</span><span class='line'>params = fw.getparams()
</span><span class='line'>nchannels, sampwidth, framerate, nframes = params[:4]
</span><span class='line'>strData = fw.readframes(nframes)
</span><span class='line'>waveData = np.fromstring(strData, dtype=np.int16)
</span><span class='line'>waveData = waveData*1.0/max(abs(waveData))  # normalization
</span><span class='line'>fw.close()
</span><span class='line'>
</span><span class='line'>frameSize = 256
</span><span class='line'>overLap = 128
</span><span class='line'>vol = vp.calVolume(waveData,frameSize,overLap)
</span><span class='line'>threshold1 = max(vol)*0.10
</span><span class='line'>threshold2 = min(vol)*10.0
</span><span class='line'>threshold3 = max(vol)*0.05+min(vol)*5.0
</span><span class='line'>
</span><span class='line'>time = np.arange(0,nframes) * (1.0/framerate)
</span><span class='line'>frame = np.arange(0,len(vol)) * (nframes*1.0/len(vol)/framerate)
</span><span class='line'>end = nframes * (1.0/framerate)
</span><span class='line'>plt.subplot(211)
</span><span class='line'>plt.plot(time,waveData)
</span><span class='line'>plt.ylabel('Amplitude')
</span><span class='line'>
</span><span class='line'>plt.subplot(212)
</span><span class='line'>plt.plot(frame,vol,color="black")
</span><span class='line'>plt.plot([0,end],[threshold1,threshold1],'-r', label="threshold 1")
</span><span class='line'>plt.plot([0,end],[threshold2,threshold2],'-g', label="threshold 2")
</span><span class='line'>plt.plot([0,end],[threshold3,threshold3],'-b', label="threshold 3")
</span><span class='line'>plt.legend()
</span><span class='line'>plt.ylabel('Volume(absSum)')
</span><span class='line'>plt.xlabel('time(seconds)')
</span><span class='line'>plt.show()</span></code></pre></td></tr></table></div></figure></notextile></div>
其中计算音量的函数calVolume参见<a href="http://ibillxia.github.io/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/">
音量及其Python实现</a>一文。程序的运行结果如下图：
<center><img src="/images/2013/IMAG2013052201.png"></center>
</p>




<p>这里采用了三种设置阈值的方法，但这几种设置方法对所有的输入都是相同的，对于一些特定的语音数据可能得不到很好的结果。下面我们利用一些更多的特征来进行
端点加测，例如使用过零率等信息。</p>




<h2>频域的端检方法</h2>


<p>有声音的信号在频谱上会有重复的谐波结构，因此我们也可以使用频谱的变化性（Variation）或Entropy来进行端点检测，可以参见如下链接：
http://neural.cs.nthu.edu.tw/jang/books/audiosignalprocessing/paper/endPointDetection/</p>




<h2>参考（References）</h2>


<p>
[1]EPD in Time Domain: http://neural.cs.nthu.edu.tw/jang/books/audiosignalprocessing/epdTimeDomain.asp?title=6-2%20EPD%20in%20Time%20Domain</br>
[2]6-3 EPD in Frequency Domain: http://neural.cs.nthu.edu.tw/jang/books/audiosignalprocessing/epdFreqDomain.asp?title=6-3%20EPD%20in%20Frequency%20Domain
</p>

]]></content>
  </entry>
  
</feed>
